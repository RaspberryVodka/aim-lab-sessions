{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe29295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the variables, classes and functions we defined in the previous lessons\n",
    "from vars.week_3 import *\n",
    "\n",
    "# Import new modules\n",
    "import torch.nn as nn \n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a2395",
   "metadata": {},
   "source": [
    "# 4. Defining simple models \n",
    "## 4.1 nn.Sequential\n",
    "The `Sequential` class is very simple: it accepts a sequence of neural network `Modules` as arguments and arranges them such that the output of one is automatically sent to the input of the next in line. This saves us a bit of time writing some code, but has some drawbacks, as we shall see shortly. The following is the simplest possible neural network. It consists only of an input layer, 1 hidden layer and an output layer. It is good practice to print out the summary of your network using `torchsummary.summary`. This lets you inspect your networks parameters and the input/output sizes of each layer. Interestingly, it also acts as a sort of sanity checker for your model, because it will complain if the input/output sizes of your layers aren't compatible with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0334b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 128]         100,480\n",
      "              ReLU-3                  [-1, 128]               0\n",
      "            Linear-4                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.39\n",
      "Estimated Total Size (MB): 0.40\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_simple_linear_net():\n",
    "    return nn.Sequential(\n",
    "        nn.Flatten(),                # Input is a 2d array of pixel values, so we flatten it out to 1d\n",
    "        nn.Linear(28*28, 128),       # Input layer connects each input node to each hidden node. MNIST images are 28*28 pixels, hidden size can be anything we want\n",
    "        nn.ReLU(),                   # ReLU activation only lets a signal through if it is > 0\n",
    "        nn.Linear(128, 10)  # Output connects each node in the hidden layer to 10 output classes - the number of digits we want to classify!\n",
    "        \n",
    "    )\n",
    "\n",
    "summary(get_simple_linear_net(), input_size=(1, 28, 28), device=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368199e5",
   "metadata": {},
   "source": [
    "### 4.1.1  Simple training loop\n",
    "Now that we've defined a network, we can start training it! Let's define the simplest possible training function, for which we only require the model, number of training epochs, the dataloader and an optimisation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5ef147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs, train_dl, optimiser):\n",
    "    msg = \"\"\n",
    "    for epoch in range(epochs):\n",
    "        total_steps = len(train_dl)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        model.train()  # set model to training mode\n",
    "        for batch_num, (image_batch, label_batch) in enumerate(train_dl):\n",
    "            # Prepare data and label batches \n",
    "            batch_sz = len(image_batch)\n",
    "            output = model(image_batch)\n",
    "            losses = nn.CrossEntropyLoss()(output, label_batch)\n",
    "            \n",
    "            # Zero gradients and backpropagate the losses\n",
    "            optimiser.zero_grad()\n",
    "            losses.backward()\n",
    "            optimiser.step()  # update model weights based on loss gradients\n",
    "\n",
    "            # Update the total number of correct predictions and calculate accuracy\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            correct += int(torch.eq(preds, label_batch).sum())\n",
    "            total += batch_sz\n",
    "            minibatch_accuracy = 100 * correct / total\n",
    "\n",
    "            #### Fancy printing stuff, you can ignore this! ######\n",
    "            if (batch_num + 1) % 5 == 0:\n",
    "                print(\" \" * len(msg), end='\\r')\n",
    "                msg = f'Train epoch[{epoch+1}/{epochs}], MiniBatch[{batch_num + 1}/{total_steps}], Loss: {losses.item():.5f}, Acc: {minibatch_accuracy:.5f}'\n",
    "                print (msg, end='\\r' if epoch < epochs else \"\\n\",flush=True)\n",
    "            #### Fancy printing stuff, you can ignore this! ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a08cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch[2/5], MiniBatch[195/394], Loss: 0.93739, Acc: 78.66987\r"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "# Defining network hyperparameters\n",
    "epochs = 5\n",
    "batch_sz = 32\n",
    "learning_rate = 0.005\n",
    "train_dl, val_dl, test_dl = load_data(DATA_PATH, batch_sz=batch_sz)   # Creating a data split\n",
    "\n",
    "network = get_simple_linear_net()                    # Creating an instance of our network\n",
    "optim = SGD(network.parameters(), lr=learning_rate)  # Stochastic gradient descent optimiser\n",
    "train_model(network, epochs, train_dl, optim)        # Calling our training function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc68cc9",
   "metadata": {},
   "source": [
    "### 4.1.2 Debrief: Simple model with simple training loop\n",
    "At the end of the training loop, our model performs pretty well - should be around 80-90% accuracy most of the time. This is definitely better than random chance, so our model seems to have learned something about the dataset and can make good predictions. But it could be better! Before we look into improving this, there is something else that needs fixing... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917d7284",
   "metadata": {},
   "source": [
    "### 4.1.3 Training device\n",
    "Something you may have noticed so far is that the training loop runs quite slowly. 5 epochs is not a very long time at all in the machine learning world and it still takes a while to complete. This because we've been asking the CPU to do all the tensor calculations needed to update the weights. This is a bad idea because GPUs are much more efficient at processing large amounts of data in parallel. You should always use a GPU to train machine learning models if one is available. Pytorch makes it very easy to detect GPU availability and transfer code you've written for a CPU to GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c94b695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # CUDA is a low-level toolkit that provides libraries for interacting with NVIDIA graphics cards\n",
    "print(f\"Using device: {device}\") # This should print out `Using device: cuda` if Pytorch detects a GPU on your system \n",
    "\n",
    "\n",
    "# We also need to modify our training loop to accept the device as an argument, and transfer input tensors to the GPU device\n",
    "def train_model_gpu(device, model, epochs, train_dl, optimiser):\n",
    "    msg = \"\"\n",
    "    for epoch in range(epochs):\n",
    "        total_steps = len(train_dl)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        model.train()\n",
    "        for batch_num, (image_batch, label_batch) in enumerate(train_dl):\n",
    "            batch_sz = len(image_batch)\n",
    "            \n",
    "            # Transferring image and label tensors to GPU #\n",
    "            image_batch = image_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "            ###############################################\n",
    "            \n",
    "            output = model(image_batch)\n",
    "            losses = nn.CrossEntropyLoss()(output, label_batch)\n",
    "                        \n",
    "            optimiser.zero_grad()\n",
    "            losses.backward()\n",
    "            optimiser.step()  \n",
    "            \n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            correct += int(torch.eq(preds, label_batch).sum())\n",
    "            total += batch_sz\n",
    "            minibatch_accuracy = 100 * correct / total\n",
    "\n",
    "            #### Fancy printing stuff, you can ignore this! ######\n",
    "            if (batch_num + 1) % 5 == 0:\n",
    "                print(\" \" * len(msg), end='\\r')\n",
    "                msg = f'Train epoch[{epoch+1}/{epochs}], MiniBatch[{batch_num + 1}/{total_steps}], Loss: {losses.item():.5f}, Acc: {minibatch_accuracy:.5f}'\n",
    "                print (msg, end='\\r' if epoch < epochs else \"\\n\",flush=True)\n",
    "            #### Fancy printing stuff, you can ignore this! ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f635bbee",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m network \u001b[38;5;241m=\u001b[39m get_simple_linear_net()\n\u001b[1;32m      3\u001b[0m optim \u001b[38;5;241m=\u001b[39m SGD(network\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m----> 4\u001b[0m network \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m train_model_gpu(device, network, epochs, train_dl, optim)\n",
      "File \u001b[0;32m~/.virtualenvs/aim-lab-sessions/lib/python3.8/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/aim-lab-sessions/lib/python3.8/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/aim-lab-sessions/lib/python3.8/site-packages/torch/nn/modules/module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 602\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.virtualenvs/aim-lab-sessions/lib/python3.8/site-packages/torch/nn/modules/module.py:925\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# Finally, we need to transfer our model to the device as well, and can begin training\n",
    "network = get_simple_linear_net()\n",
    "optim = SGD(network.parameters(), lr=learning_rate)\n",
    "network = network.to(device)\n",
    "train_model_gpu(device, network, epochs, train_dl, optim)\n",
    "\n",
    "# You should see a speedup in training speed!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
