{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a78902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "MODEL_DIR = \"./saved_models\"\n",
    "DATASET_PREFIX = \"./data/MNIST\"\n",
    "DATA_PATH = f\"{DATASET_PREFIX}/raw/mnist_dataset.csv\"\n",
    "CHECKPOINT_FREQ = 5\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "NUM_CLASSES = 10\n",
    " \n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    def load_image_tensor(filepath):\n",
    "        img = Image.open(filepath)\n",
    "        transform = transforms.Compose([\n",
    "            transforms.PILToTensor()\n",
    "        ])\n",
    "        img_tensor = transform(img)\n",
    "        return img_tensor.to(DEVICE)\n",
    "\n",
    "    images_tensor = torch.cuda.FloatTensor(len(batch), 28, 28)\n",
    "    torch.cat([load_image_tensor(f\"{DATASET_PREFIX}/{item[0]}\") for item in batch], out=images_tensor)\n",
    "    labels_tensor = torch.cuda.FloatTensor([item[1] for item in batch])\n",
    "    return (images_tensor.to(DEVICE), labels_tensor.type(torch.int64).to(DEVICE))\n",
    "\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, filepath: str):\n",
    "        super().__init__()\n",
    "        self.dataframe = pd.read_csv(filepath)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataframe.iloc[idx]\n",
    "\n",
    "    \n",
    "def load_data(batch_sz=100, train_val_test_split=[0.8, 0.1, 0.1]):\n",
    "    assert sum(train_val_test_split) == 1, \"Train, val and test fractions should sum to 1!\"\n",
    "    train_dataset = MNISTDataset(DATA_PATH)\n",
    "    train_val_split = list(map(lambda split: round(split * len(train_dataset)), train_val_test_split))\n",
    "    train_split, val_split, test_split = random_split(train_dataset, train_val_split)\n",
    "    train_dl = DataLoader(train_split, \n",
    "                          batch_size=batch_sz, \n",
    "                          shuffle=True, \n",
    "                          collate_fn=custom_collate_fn)\n",
    "    val_dl = DataLoader(val_split, \n",
    "                        batch_size=batch_sz, \n",
    "                        shuffle=True, \n",
    "                        collate_fn=custom_collate_fn)\n",
    "    test_dl = DataLoader(test_split,\n",
    "                         batch_size=batch_sz,\n",
    "                         shuffle=False,\n",
    "                         collate_fn=custom_collate_fn)\n",
    "    return train_dl, val_dl, test_dl\n",
    "                \n",
    "    \n",
    "def image_grid(dataset, ncols=4):\n",
    "    images_only = dataset\n",
    "    height, width = dataset[0].shape\n",
    "    nrows = len(images_only)//ncols\n",
    "    \n",
    "    img_grid = (dataset.reshape(nrows, ncols, height, width)\n",
    "              .swapaxes(1,2)\n",
    "              .reshape(height*nrows, width*ncols))\n",
    "    \n",
    "    return img_grid\n",
    "\n",
    "\n",
    "def show_batch(dataset, title=\"Image batch\", cols=4):\n",
    "    N = len(dataset)\n",
    "    if N > cols:\n",
    "        assert N % cols == 0, \"Number of cols must be a multiple of N\"\n",
    "    \n",
    "    result = image_grid(dataset)\n",
    "    fig = plt.figure(figsize=(5., 5.))\n",
    "    plt.suptitle(f\"{title} [{int(N/cols)}x{cols}]\")\n",
    "    plt.imshow(result.cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89411019",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl, test_dl = load_data(batch_sz=16)\n",
    "\n",
    "train_images, _ = next(iter(train_dl))\n",
    "test_images, _ = next(iter(test_dl))\n",
    "\n",
    "show_batch(train_images, title=\"Train images\", cols=4)\n",
    "show_batch(test_images, title=\"Test images\", cols=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee77267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "\n",
    "def save_model(model, epoch, save_dir):\n",
    "    filename = f\"checkpoint_{epoch}.pth\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    torch.save(model, save_path)\n",
    "\n",
    "\n",
    "\n",
    "simple_seq_net = nn.Sequential(\n",
    "    nn.Conv2d(\n",
    "        \n",
    "        in_channels=1,              \n",
    "        out_channels=16,            \n",
    "        kernel_size=5,              \n",
    "        stride=1,                   \n",
    "        padding=2,                  \n",
    "    ),                              \n",
    "    nn.ReLU(),                      \n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "    nn.ReLU(),                      \n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(32 * 7 * 7, NUM_CLASSES)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690b5d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample):\n",
    "        super().__init__()\n",
    "        if downsample:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "            self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        shortcut = self.shortcut(inp)\n",
    "        inp = nn.ReLU()(self.bn1(self.conv1(inp)))\n",
    "        inp = nn.ReLU()(self.bn2(self.conv2(inp)))\n",
    "        inp = inp + shortcut\n",
    "        return nn.ReLU()(inp)\n",
    "    \n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels, resblock, outputs):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            resblock(64, 64, downsample=False),\n",
    "            resblock(64, 64, downsample=False)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            resblock(64, 128, downsample=True),\n",
    "            resblock(128, 128, downsample=False)\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            resblock(128, 256, downsample=True),\n",
    "            resblock(256, 256, downsample=False)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            resblock(256, 512, downsample=True),\n",
    "            resblock(512, 512, downsample=False)\n",
    "        )\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flat = nn.Flatten() \n",
    "        self.fc = nn.Linear(512, outputs)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        inp = self.layer0(inp)\n",
    "        inp = self.layer1(inp)\n",
    "        inp = self.layer2(inp)\n",
    "        inp = self.layer3(inp)\n",
    "        inp = self.layer4(inp)\n",
    "        inp = self.gap(inp)\n",
    "        inp = self.flat(inp)\n",
    "        inp = self.fc(inp)\n",
    "\n",
    "        return inp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b46b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "# Need to work in Early stopping (https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch) and Learning Rate scheduling (https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate)\n",
    "def train_model(model, epochs, dataloaders, checkpoint_frequency=5):\n",
    "    writer = SummaryWriter()\n",
    "    for epoch in range(epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            total_steps = len(dataloaders[phase])\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for batch_num, (image_batch, label_batch) in enumerate(dataloaders[phase]):\n",
    "                optim.zero_grad()\n",
    "                batch_sz = len(image_batch)\n",
    "                image_batch = image_batch.reshape(batch_sz, 1, 28, 28)            \n",
    "\n",
    "\n",
    "                output = model(image_batch)\n",
    "                losses = loss_fn(output, label_batch)\n",
    "\n",
    "                if phase == \"train\":\n",
    "                    losses.backward()\n",
    "                    optim.step()\n",
    "\n",
    "\n",
    "                preds = torch.argmax(output, dim=1)\n",
    "                correct += int(torch.eq(preds, label_batch).sum())\n",
    "                total += label_batch.shape[0]\n",
    "                writer.add_scalar(f'Loss/{phase}', losses.item(), (epoch*epochs) + batch_num)\n",
    "                if (batch_num + 1) % 10 == 0:\n",
    "                    print (f'Epoch[{epoch+1}/{epochs}], Step[{batch_num + 1}/{total_steps}], Loss({phase}): {losses.item():.4f}, Acc({phase}): {correct/total:.3f}',\n",
    "                           end=\"\\r\" if epoch < epochs else \"\\n\", \n",
    "                           flush=True)\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "            writer.add_scalar(f'Acc/{phase}', accuracy, epoch)\n",
    "            if phase == \"val\":\n",
    "                if (epoch + 1) % checkpoint_frequency == 0:\n",
    "                    save_model(model, epoch + 1, \"./saved_models\")\n",
    "                    \n",
    "\n",
    "def test_model(model, dataloaders):\n",
    "    writer = SummaryWriter()\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_steps = len(dataloaders['test'])\n",
    "    for batch_num, (image_batch, label_batch) in enumerate(dataloaders['test']):\n",
    "        batch_sz = len(image_batch)\n",
    "        image_batch = image_batch.reshape(batch_sz, 1, 28, 28)\n",
    "        out = model(image_batch)\n",
    "        preds = torch.argmax(out, dim=1)\n",
    "        correct += int(torch.eq(preds, label_batch).sum())\n",
    "        total += label_batch.shape[0]\n",
    "        if (batch_num + 1) % 10 == 0:\n",
    "            print (f'Testing batch[{batch_num + 1}/{total_steps}]',\n",
    "                   end=\"\\r\" if batch_num < total_steps else \"\\n\", \n",
    "                   flush=True)\n",
    "    print(f\"Final test accuracy for {total} examples: {correct/total:.3f}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f311721",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "train_batch_sz = val_batch_sz = 128\n",
    "learning_rate = 0.001 \n",
    "\n",
    "train_dl, val_dl, test_dl = load_data(batch_sz=train_batch_sz)\n",
    "dataloaders = {'train': train_dl, 'val': val_dl, 'test': test_dl}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "network = ResNet(1, ResBlock, outputs=NUM_CLASSES)\n",
    "# network = simple_seq_net\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(network.parameters(), lr=learning_rate)\n",
    "network = network.to(DEVICE)\n",
    "\n",
    "\n",
    "train_model(network, epochs, dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e76ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_net = torch.load(\"./saved_models/checkpoint_15.pth\")\n",
    "test_model(loaded_net, dataloaders)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
