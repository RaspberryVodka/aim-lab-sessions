{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aedea4b",
   "metadata": {},
   "source": [
    "# 2. Pandas\n",
    "\n",
    "In this exercise, we will be looking at pandas, a Python library that provides many useful tools for loading, displaying, and cleaning data.  \n",
    "\n",
    "To aid us in showing off the functionality of this library, we will be looking at the MetObjects dataset, which comes courtesy of the Metropolitan Museum of Art in New York [https://www.metmuseum.org/]. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08bba43",
   "metadata": {},
   "source": [
    "## 2.1 Downloading the dataset\n",
    "You can use a leading `!` in a line of Jupyter notebook code to specify that the rest of the line should be interpreted as a shell command. This is convenient for modifying files or running scripts that live on your filesystem without having to switch between the browser and terminal. Let's use this syntax to download the Met Museum dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab33955",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = ''   # Normal python code\n",
    "\n",
    "\n",
    "# Jupyter notebook \"magic\" lines prepended with a ! character\n",
    "\n",
    "# Dataset \n",
    "MET_DATA_PATH = \"./data/metmuseum/MetObjects.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c44439d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Module imports and plot settings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.mode.chained_assignment = None \n",
    "plt.rcParams[\"figure.figsize\"] = [8, 7]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bf7aa6",
   "metadata": {},
   "source": [
    "## 2.2 The DataFrame\n",
    "\n",
    "The DataFrame is the central data structure provided by Pandas, and it is this structure that we need to interrogate when we want to ask questions about our data. You can think of a DataFrame as a table with rows of records and columns that describe the fields of those records. Pandas provides built in functions for loading text files and automatically puts their contents into a DataFrame. The dataset we just downloaded (`MetObjects.csv`) is a CSV (comma separated value) file, so we need to use the `load_csv` function provided by Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf93f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a look at the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61918256",
   "metadata": {},
   "source": [
    "## 2.3 Accessing and displaying data\n",
    "\n",
    "### 2.3.1 Integer indexing\n",
    "Similar to Python list slices, uses 0-indexed start and end positions to return a subset of the dataframe. With a Padas dataframe, this is done via the `iloc` indexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7850dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows number 29 to 35\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d635ad",
   "metadata": {},
   "source": [
    "### 2.3.2 Boolean Series\n",
    "A series is a 1-D array - a boolean series is one that is filled with boolean (i.e., `True` or `False`) values. We can pass boolean series into a Dataframe's `loc` indexer to keep only the values that align with `True`. Different boolean series of the same length can be combined using the following logical operators: `&` (and), `|` (or), `~` (not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a44d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all rows from the 'Medieval Art' department\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5bbdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rows from the 'Medieval Art' OR 'European Sculpture and Decorative Arts' departments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dc5622",
   "metadata": {},
   "source": [
    "### 2.3.3 Grouping by column name(s)\n",
    "We can also group the data by a list of columns. This returns a Pandas GroupBy object, which contains a dictionary of mappings from each group name to a Series of its elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826cbccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e70fcf8",
   "metadata": {},
   "source": [
    "### 2.3.4 Using `where`\n",
    "Similar to Numpy arrays, Pandas dataframes also make use of the `where` function to conditionally modify its elements based on some criteria. `where` takes a dataframe condition as an argument and returns the modified dataframe - if the condition is fulfilled, it keeps the value of the field, if not, it replaces it with `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef951f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fffb35c4",
   "metadata": {},
   "source": [
    "## 2.4 Data cleaning\n",
    "\n",
    "We can see that there are several problems with the dataset right off the bat:\n",
    "1. First row seems to contain garbage: none of the column names match up with the data types, and many are NaN\n",
    "2. It looks like many of the columns are completely empty - they add nothing to the dataset but clutter it\n",
    "3. Too many columns! This depends on what your needs are, but we don't need all of them for this exercise\n",
    "4. Inconsistent formatting in the Dimensions column - makes it difficult to use them downstream\n",
    "5. Mixed datatypes in Year fields\n",
    "\n",
    "Let's address all of these issues one by one\n",
    "\n",
    "### 2.4.1 Deleting rows by index\n",
    "We can get rid of the first row (index 0) by taking a slice of the dataframe beginning at index 1 and going all the way to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2579d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of the first row, we can use dataframe slicing to accomplish this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c2dc44",
   "metadata": {},
   "source": [
    "### 2.4.2 Removing columns\n",
    "\n",
    "Columns can be removed conditionally by checking their contents to see if they meet a certain criteria, or simply by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88098fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of all columns that are completely empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf399e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, we can also drop the columns that are irrelevant to our needs\n",
    "exclude_cols = [\n",
    "    \"Country\",\n",
    "    \"Culture\",\n",
    "    \"Is Highlight\",\n",
    "    \"Is Timeline Work\",\n",
    "    \"Object End Date\",\n",
    "    \"Gallery Number\",\n",
    "    \"Period\",\n",
    "    \"Constituent ID\",\n",
    "    \"Artist Role\",\n",
    "    \"Artist Prefix\",\n",
    "    \"Artist Display Name\",\n",
    "    \"Artist Display Bio\",\n",
    "    \"Artist Suffix\",\n",
    "    \"Artist Alpha Sort\",\n",
    "    \"Artist Gender\",\n",
    "    \"Artist Nationality\",\n",
    "    \"Artist ULAN URL\",\n",
    "    \"Artist Wikidata URL\",\n",
    "    \"Credit Line\",\n",
    "    \"Object ID\",\n",
    "    \"Geography Type\",\n",
    "    \"City\",\n",
    "    \"State\",\n",
    "    \"County\",\n",
    "    \"Region\",\n",
    "    \"Classification\",\n",
    "    \"Rights and Reproduction\",\n",
    "    \"Link Resource\",\n",
    "    \"Object Wikidata URL\",\n",
    "    \"Repository\",\n",
    "    \"Tags AAT URL\",\n",
    "    \"Tags Wikidata URL\",\n",
    "    \"Artist Begin Date\",\n",
    "    \"Artist End Date\",\n",
    "    \"Object Date\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab73dee",
   "metadata": {},
   "source": [
    "### 2.4.3 Removing rows\n",
    "We can also get rid of rows that do not meet certain criteria. For example, given a subset of fields that we deem very important, we can drop all rows are NaN in any of these fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f4eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping records (rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaa9969",
   "metadata": {},
   "source": [
    "### 2.4.4 Applying functions to columns\n",
    "\n",
    "We noted earlier that the Dimensions field is a bit messy (inconsistent mixing of imperial and metric units).  We need it to have consistent formatting so that any functions we write later can work with the values without any complicated processing. Doing the complicated work up front saves a lot of time down the line! Don't worry too much about how exactly this function works. This is just to show that we can write arbitrarily complex cleaning functions and apply it to a Dataframe's columns. The important thing to note about this function is that if it can't find a suitable dimension to extract for whatever reason, **it will fail, and on failure will return NaN** (not a number).  \n",
    "\n",
    "When this function is applied to the Dimensions column, the column will be left with values that look like:\n",
    "1. a OR\n",
    "2. a, b OR\n",
    "3. a, b, c OR\n",
    "4. NaN\n",
    "\n",
    "where a, b and c are lengths in centimetres and NaN is an indication that the extraction function has failed\n",
    "\n",
    "We can apply this function using the DataFrame's `apply` method. This takes the function to be applied, along with any additional arguments (In addition to the value of the column, of course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2266f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Defining the function that will be used to extract metric dimensions. The first argument to\n",
    "# the function must be the value in the column. \n",
    "def extract_dimensions(dim_str):\n",
    "    dimensions_exp = r\"(?<=\\()( *\\d.+?)(?=cm\\))\"\n",
    "    delimiter_exp = r\"(?:\\d+\\.?\\d* *)([^\\.\\n])(?: *\\d+\\.?\\d* *)?(?:[^\\.\\n] *\\d+\\.?\\d*)?\"\n",
    "    retval = np.nan\n",
    "    try:\n",
    "        dim_str = dim_str.split(\"\\n\")[0]\n",
    "        dimensions = re.search(dimensions_exp, dim_str).group(0)\n",
    "        delimiter = re.search(delimiter_exp, dimensions.strip()).groups()[0]\n",
    "        if not delimiter.isnumeric():\n",
    "            # There are multiple dimensions\n",
    "            retval = ','.join(dimensions.split(delimiter))\n",
    "        else:\n",
    "            retval = dimensions\n",
    "    except AttributeError as e:\n",
    "        pass\n",
    "    finally:\n",
    "        return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2aa2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise the dimensions of the pieces\n",
    "\n",
    "# Because extract_dimensions can fail and return NaN, we also need to remove any records where Dimensions is NaN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deff332",
   "metadata": {},
   "source": [
    "### 2.4.5 Default values\n",
    "Artists are known to often leave their work untitled (why??). In our dataset, this is not handled very gracefully - the titles of such artworks are simple NaN. Fortunately, we have another way of dealing with missing data: assinging a default value. We can replace any instance of a NaN title with the string \"Untitled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f8ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting default values. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf99cdc",
   "metadata": {},
   "source": [
    "### 2.4.6 Data types\n",
    "We change some data types that don't really make sense: `AccessionYear` and `Object Begin Date` were originally loaded in with mixed datatypes (some are strings, some are numbers), which makes it difficult to sort correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b60800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Finally, we can sort a dataframe based on the values in a specific column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e59d5bd",
   "metadata": {},
   "source": [
    "## 2.5 Dataframe interrogation\n",
    "We can now begin to ask some interesting questions about this dataset:\n",
    "1. Which department houses the oldest artwork in the museum? Use `Object Begin Date` for this task.\n",
    "2. What is the proportion of artworks from each department? Display this graphically using `pd.DataFrame.plot.pie`\n",
    "3. What is the average area in $cm^2$ of Paintings in the Asian Art department?\n",
    "4. _What is the most common theme across all the paintings? Or, which tag is most common?_\n",
    "5. _How many artworks were delivered to the museum each decade, and what department took them?_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ac12f8",
   "metadata": {},
   "source": [
    "### 2.5.1 Exercise\n",
    "Oldest artwork in the museum \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a05e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataset by `Object Begin Date`  \n",
    "\n",
    "# Get the first element "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409617cd",
   "metadata": {},
   "source": [
    "### 2.5.2 Exercise\n",
    "Proportion of artworks from each department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ba3d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataset by `Department`\n",
    "\n",
    "# Get the sizes of each grouping and put them in a coulumn called `Counts` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a62db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw as pie chart - Just run this cell to see the output of your grouping :)\n",
    "departments.plot.pie(y=\"Counts\", \n",
    "                     explode=[0.125 for _ in range(len(departments))], \n",
    "                     labels=departments['Department'], \n",
    "                     legend=None, ylabel=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea28a8f",
   "metadata": {},
   "source": [
    "### 2.5.3 Question 3\n",
    "Let's tackle Q3: What is the average area in $cm^2$ of Paintings in the Asian wing? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a5efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the pieces that belong to the Asian Art department AND are paintings\n",
    "asian_art_bool_series = ...\n",
    "painting_bool_series = ...\n",
    "asian_paintings = ...\n",
    "asian_paintings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ae665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Define an area calculation function to each item in the Dimensions column\n",
    "def calc_area(dim_string):\n",
    "    # Note that some paintings are listed as having only 1 dimension - here we can assume that they are \n",
    "    # circular and that the given dimension is its diameter (and probably not radius as that cannot be measured as easily)\n",
    "    \n",
    "    # extract dimensions from the string and place them into a list\n",
    "    dims_separated = ... \n",
    "    if len(dims_separated) == 1:\n",
    "        # We have a circular painting, apply the circular area formula\n",
    "        diameter = ...  # dimensions are strings, so need to be converted to floats\n",
    "        radius = ...\n",
    "        area = ...\n",
    "        return area\n",
    "    elif len(dims_separated) >= 2:\n",
    "        # We have a rectangular painting, use the rectangular area formula\n",
    "        # Some paintings probably have a 3rd dimension to indicate the depth\n",
    "        # of its frame, we can ignore this and only take the first 2 elements\n",
    "        width  = ...\n",
    "        height = ...\n",
    "        area = ...\n",
    "        return area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb5dd80",
   "metadata": {},
   "source": [
    "Test out your function here on some random dimension strings to see if it works! Once you're satisfied that you've got it working, you can move on. If you want some inspiration for inputs, use these:\n",
    "* \"83, 99, 3\"\n",
    "* \"10\"\n",
    "* \"abc\"\n",
    "* \"55, 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af65520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply your function to the DataFrame and assign its results to a new column `Area` within\n",
    "# the same dataframe\n",
    "asian_paintings['Area']  = ...\n",
    "asian_paintings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a22b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean of the `Area` column\n",
    "average_area = ...\n",
    "average_area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867b9111",
   "metadata": {},
   "source": [
    "### 2.5.4 Question 4\n",
    "What is the most common theme across all the paintings? Or, which tag is most common?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0686c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare an empty list to collect all the separated tags in the database\n",
    "tags_list = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95b531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Tags series out of the dataset and assign it to a variable\n",
    "# called tags_series\n",
    "tags_series = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d97cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function:\n",
    "def update_list(t, l):\n",
    "    pass\n",
    "\n",
    "# Apply function to tags_series\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the tags list to instantiate a dataframe called tags_df\n",
    "tags_df = ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347afc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the dataframe by Tag and count the occurences of each tag\n",
    "tags_df = ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9679f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the list by count to find the one with the tag with the \n",
    "# highest number of occurences\n",
    "tags_df = ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
